{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import etree as ET\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пути к каталогам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "XML_TRAINING_FILE_PATH = \"./data/train.xml\"\n",
    "XML_TEST_FILE_PATH = \"./data/test.xml\"\n",
    "PREDICTED_RESULT_PATH = \"./data/result.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Извлечение информации из XML-файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_xml(path):\n",
    "    \"\"\"\n",
    "    Функция загружает данные из XML-файла, возвращает список слов и меток.\n",
    "\n",
    "    :param path: путь к файлу\n",
    "    :return: список слов и список меток\n",
    "    \"\"\"\n",
    "    word_cnt_in_sentence = 1\n",
    "    curr_parent = 0\n",
    "    words = []\n",
    "    labels = []\n",
    "    cnt = 0\n",
    "\n",
    "    for action, word in ET.iterparse(path, tag=\"word\"):\n",
    "        try:\n",
    "            features = {\n",
    "                \"word\": word.get(\"original\"),  # Исходное слово: <word original/>\n",
    "                \"phrasal_stress\": True if word.get(\"nucleus\") else False,\n",
    "                \"pause\": False,\n",
    "                \"pause_len\": -1,\n",
    "            }\n",
    "\n",
    "            dictitem = word.find(\"dictitem\")\n",
    "\n",
    "            # Род и одушевленность слова <word genesys/>, <dictitem genesys/>\n",
    "            features[\"genesys\"] = dictitem.get(\"genesys\")\n",
    "\n",
    "            # Значения семантики слова: теги: <word>, <dictitem>, атрибуты: semantics1, semantics2\n",
    "            features[\"semantics1\"] = dictitem.get(\"semantics1\")\n",
    "            features[\"semantics2\"] = dictitem.get(\"semantics2\")\n",
    "\n",
    "            # Части речи слов, теги <word>, <dictitem>, subpart_of_speech\n",
    "            features[\"subpart_of_speech\"] = dictitem.get(\"subpart_of_speech\")\n",
    "\n",
    "            # Формы слова (тег <word> тег <dictitem>, form).\n",
    "            features[\"form\"] = dictitem.get(\"form\")\n",
    "\n",
    "            # Информация о слове: гласные, Ё, прописные/строчные … (тег <word> тег <letter> для группы букв).\n",
    "            letters = []\n",
    "            for letter in word.findall(\"letter\"):\n",
    "                if letter.get(\"char\") is not None:\n",
    "                    letters.append(letter.get(\"char\"))\n",
    "\n",
    "            if len(letters) == 0:\n",
    "                letters = list(features[\"word\"])\n",
    "\n",
    "            features[\"length\"] = len(letters)\n",
    "            features[\"vowels_sounds\"] = sum(\n",
    "                1 if letter in \"аоиыуэАОИЫУЭ\" else 0 for letter in letters\n",
    "            )\n",
    "            features[\"vowels_letters\"] = sum(\n",
    "                1 if letter in \"аяуюоеёэиыАЯУЮОЕЁЭИЫ\" else 0 for letter in letters\n",
    "            )\n",
    "\n",
    "            # Знаки препинания и эмфазы на слове (тег <content>, PunktEnd, PunktBeg, EmphEnd, EmphBeg).\n",
    "            content = word.getprevious()\n",
    "            features[\"PunktEnd\"] = content.get(\"PunktEnd\")\n",
    "            features[\"PunktBeg\"] = content.get(\"PunktBeg\")\n",
    "            features[\"EmphEnd\"] = content.get(\"EmphEnd\")\n",
    "            features[\"EmphBeg\"] = content.get(\"EmphBeg\")\n",
    "\n",
    "            if curr_parent == 0:\n",
    "                curr_parent = word.getparent()[1]\n",
    "            elif curr_parent == word.getparent()[1]:\n",
    "                word_cnt_in_sentence += 1\n",
    "            else:\n",
    "                word_cnt_in_sentence = 1\n",
    "                curr_parent = word.getparent()[1]\n",
    "\n",
    "            # сколько слов в предложении до текущего\n",
    "            features[\"words_before\"] = word_cnt_in_sentence - 1\n",
    "\n",
    "            pause = None\n",
    "            if word.getnext() is not None:\n",
    "                if word.getnext().tag == \"pause\":\n",
    "                    pause = word.getnext()\n",
    "                elif (\n",
    "                    word.getnext().getnext() is not None\n",
    "                    and word.getnext().getnext().tag == \"pause\"\n",
    "                ):\n",
    "                    pause = word.getnext().getnext()\n",
    "\n",
    "            label = [\n",
    "                \"undefined\"\n",
    "                if pause is None\n",
    "                else pause.get(\n",
    "                    \"type\"\n",
    "                ),  # тип паузы, если добавляем отсутствующую паузу после слова, то undefined.\n",
    "                0\n",
    "                if pause is None or pause.get(\"time\") is None\n",
    "                else pause.get(\"time\"),  # время паузы\n",
    "                0\n",
    "                if pause is None\n",
    "                else 1,  # есть ли пауза после текущего слова или нет 1/0.\n",
    "                0 if word.get(\"nucleus\") is None else word.get(\"nucleus\"),\n",
    "            ]  # те самые нуклеус, если в word есть nucleus, то переносим в список, если нет то ставим 0.\n",
    "\n",
    "            labels.append(label)\n",
    "\n",
    "            words.append(features)\n",
    "\n",
    "            word.clear()\n",
    "\n",
    "        except:\n",
    "            cnt += 1\n",
    "    print(\"Количество исключений:\", cnt)\n",
    "    return labels, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество исключений: 0\n"
     ]
    }
   ],
   "source": [
    "labels, words = read_xml(XML_TRAINING_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['undefined', 0, 0, 0],\n",
       " ['undefined', 0, 0, 0],\n",
       " ['undefined', 0, 0, 0],\n",
       " ['x-long', '1020', 1, '2'],\n",
       " ['undefined', 0, 0, 0]]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 'ПРЕДИСЛОВИЕ',\n",
       " 'phrasal_stress': False,\n",
       " 'pause': False,\n",
       " 'pause_len': -1,\n",
       " 'genesys': '6',\n",
       " 'semantics1': None,\n",
       " 'semantics2': None,\n",
       " 'subpart_of_speech': '1',\n",
       " 'form': '1',\n",
       " 'length': 11,\n",
       " 'vowels_sounds': 3,\n",
       " 'vowels_letters': 5,\n",
       " 'PunktEnd': None,\n",
       " 'PunktBeg': None,\n",
       " 'EmphEnd': None,\n",
       " 'EmphBeg': None,\n",
       " 'words_before': 0}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Преобразование информации в признаки для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(words):\n",
    "    keys = list(words[0].keys())[4:]\n",
    "    df = pd.DataFrame([{k: word[k] if word[k] is not None else 0 for k in keys} for word in words])\n",
    "    scaler = MinMaxScaler()\n",
    "    features = scaler.fit_transform(df)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_labels(labels):\n",
    "    pause_type = [element[0] for element in labels]\n",
    "    pause_time = [element[1] for element in labels]\n",
    "    pause = [element[2] for element in labels]\n",
    "    phrasal_stress = [element[3] for element in labels]\n",
    "    phrasal_stress_binary = []\n",
    "    for i in phrasal_stress:\n",
    "        if i == 0:\n",
    "            i = \"False\"\n",
    "        else:\n",
    "            i = \"True\"\n",
    "        phrasal_stress_binary.append(i)\n",
    "    return pause_type, pause_time, pause, phrasal_stress, phrasal_stress_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = get_features(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pause_type, pause_time, pause, phrasal_stress, phrasal_stress_binary = get_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pause_time= list(map(lambda x : int(x), pause_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание мест пауз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Балансировка датасета c методом overSample\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over, y_pause_over = oversample.fit_resample(features, pause)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      9853\n",
      "           1       0.95      0.98      0.96      9855\n",
      "\n",
      "    accuracy                           0.96     19708\n",
      "   macro avg       0.96      0.96      0.96     19708\n",
      "weighted avg       0.96      0.96      0.96     19708\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_over, y_pause_over, test_size=0.2, random_state=42)\n",
    "clf_pause = RandomForestClassifier(random_state=42)\n",
    "clf_pause.fit(X_train,Y_train)\n",
    "pred_pause = clf_pause.predict(X_test)\n",
    "print(classification_report(Y_test, pred_pause))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание длительности пауз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8463472855112936"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pause_time, X_test_pause_time, Y_train_pause_time, Y_test_pause_time = train_test_split(features, pause_time, test_size=0.2, random_state=42)\n",
    "regressor_pause_time = RandomForestRegressor(random_state=42)\n",
    "regressor_pause_time.fit(X_train_pause_time, Y_train_pause_time)\n",
    "regressor_pause_time.score(X_test_pause_time, Y_test_pause_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pause_time = regressor_pause_time.predict(X_test_pause_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание мест фразового ударения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over, y_phrasal_stress_binary_over = oversample.fit_resample(features, phrasal_stress_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.94      0.95      9839\n",
      "        True       0.94      0.97      0.96      9861\n",
      "\n",
      "    accuracy                           0.96     19700\n",
      "   macro avg       0.96      0.96      0.96     19700\n",
      "weighted avg       0.96      0.96      0.96     19700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_phrasal_stress, X_test_phrasal_stress, Y_train_phrasal_stress, Y_test_phrasal_stress = train_test_split(X_over, y_phrasal_stress_binary_over, test_size=0.2, random_state=42)\n",
    "clf_phrasal_stress = RandomForestClassifier(random_state=42)\n",
    "clf_phrasal_stress.fit(X_train_phrasal_stress,Y_train_phrasal_stress)\n",
    "pred_phrasal_stress = clf_phrasal_stress.predict(X_test_phrasal_stress)\n",
    "print(classification_report(Y_test_phrasal_stress, pred_phrasal_stress))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предсказание на тестовом файле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество исключений: 0\n"
     ]
    }
   ],
   "source": [
    "_, test_words = read_xml(XML_TEST_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = get_features(test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pause = clf_pause.predict(test_features)\n",
    "pred_pause_time = regressor_pause_time.predict(test_features)\n",
    "pred_phrasal_stress = clf_phrasal_stress.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pause_time= list(map(lambda x : int(x), pred_pause_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(len(test_words)):\n",
    "    record = {\"content\":test_words[i][\"word\"]}\n",
    "    if pred_pause[i] == 0:\n",
    "        record[\"pause_len\"] = -1\n",
    "    else:\n",
    "        record[\"pause_len\"] = int(pred_pause_time[i])\n",
    "    record[\"phrasal_stress\"] = pred_phrasal_stress[i]\n",
    "    results.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PREDICTED_RESULT_PATH, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump([{\"words\": results}], json_file, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
