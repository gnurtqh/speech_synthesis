{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-21T12:49:17.256345Z",
          "iopub.status.busy": "2023-11-21T12:49:17.256058Z",
          "iopub.status.idle": "2023-11-21T12:49:20.806357Z",
          "shell.execute_reply": "2023-11-21T12:49:20.805452Z",
          "shell.execute_reply.started": "2023-11-21T12:49:17.256319Z"
        },
        "id": "04mT2sJzp_cl",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from lxml import etree as ET\n",
        "from typing import Optional\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBkZrmPssxBG",
        "outputId": "d4ab5208-0ccd-47f0-e24e-033bcf1a69ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece\n",
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-11-21T12:49:20.808665Z",
          "iopub.status.busy": "2023-11-21T12:49:20.808164Z",
          "iopub.status.idle": "2023-11-21T12:49:24.481118Z",
          "shell.execute_reply": "2023-11-21T12:49:24.479939Z",
          "shell.execute_reply.started": "2023-11-21T12:49:20.808631Z"
        },
        "id": "qWAwA1I3p_cn",
        "outputId": "339b7f02-9448-4ecc-9dff-5ec1ead0aac7",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: wandb: command not found\n"
          ]
        }
      ],
      "source": [
        "!wandb login 84ade52cdbc9e028a7bc45589dd701fc1e063a3e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3QabzESp_co"
      },
      "source": [
        "# Извлечение информаций из файла XML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-21T12:49:24.483159Z",
          "iopub.status.busy": "2023-11-21T12:49:24.482764Z",
          "iopub.status.idle": "2023-11-21T12:49:24.493110Z",
          "shell.execute_reply": "2023-11-21T12:49:24.492259Z",
          "shell.execute_reply.started": "2023-11-21T12:49:24.483118Z"
        },
        "id": "Jz8CQtGyp_cp",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def parse_xml_file(path: str) -> tuple[list[list], list[list]]:\n",
        "    \"\"\"\n",
        "    Parses an XML file and extracts information about words and allophones.\n",
        "\n",
        "    Args:\n",
        "    - xml_path (str): The path to the XML file.\n",
        "\n",
        "    Returns:\n",
        "    - lists: 2 lists of words and allophones\n",
        "    \"\"\"\n",
        "    allophones = []\n",
        "    words = []\n",
        "\n",
        "    for event, sentence in ET.iterparse(path, tag=\"sentence\"):\n",
        "        sentence_words = []\n",
        "        sentence_allophones = []\n",
        "        for word in sentence.findall('word'):\n",
        "            word_allophone = [item.get('ph') for item in word.findall(\"allophone\")]\n",
        "            sentence_allophones.append(word_allophone)\n",
        "            sentence_words.append(word.get('original'))\n",
        "            word.clear()\n",
        "        words.append(sentence_words)\n",
        "        allophones.append(sentence_allophones)\n",
        "    return words, allophones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-21T12:49:24.496355Z",
          "iopub.status.busy": "2023-11-21T12:49:24.495701Z",
          "iopub.status.idle": "2023-11-21T12:49:30.076122Z",
          "shell.execute_reply": "2023-11-21T12:49:30.075256Z",
          "shell.execute_reply.started": "2023-11-21T12:49:24.496322Z"
        },
        "id": "GKv0TWD5p_cq",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "words, allophones = parse_xml_file('/content/drive/MyDrive/data/speech_synthesis/train.xml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xp9vUD42p_cq",
        "outputId": "315bd474-2bf2-4aac-c1f8-113fa52e1641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ПРЕДИСЛОВИЕ', 'К', 'РУССКОМУ', 'ПЕРЕВОДУ']\n"
          ]
        }
      ],
      "source": [
        "print(words[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPzyBwYkp_cq",
        "outputId": "1ed975ba-cd54-446f-fbba-d69f5c680642"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['p', \"r'\", 'i1', \"d'\", 'i1', 's', 'l', 'o0', \"v'\", 'i4', 'j', 'i4'], ['k'], ['r', 'u0', 's', 'k', 'a4', 'm', 'u4'], [\"p'\", 'i1', \"r'\", 'i1', 'v', 'o0', 'd', 'u4']]\n"
          ]
        }
      ],
      "source": [
        "print(allophones[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tpJd3p8Op_cr"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from typing import Optional\n",
        "\n",
        "def create_feature(words: list[list], allophones: list[list] = None) -> Optional[tuple[list, list]]:\n",
        "    \"\"\"\n",
        "    Create a phrase consisting of the root word and the word that immediately follows it\n",
        "\n",
        "    Args:\n",
        "    - words (list): list of words of sentences\n",
        "    - allophones (int): list of allophones of words\n",
        "\n",
        "    Returns:\n",
        "    - 2 lists of phrases consisting of the root word and the word that immediately follows it and allophones\n",
        "    \"\"\"\n",
        "    train_words = []\n",
        "    train_allophones = []\n",
        "\n",
        "    for i in range(len(words)):\n",
        "        for j in range(len(words[i])):\n",
        "            if words[i][j] != None and not words[i][j].isnumeric():\n",
        "                if j + 1 == len(words[i]):\n",
        "                    current_word = words[i][j]\n",
        "                else:\n",
        "                    if words[i][j+1] != None and not words[i][j+1].isnumeric():\n",
        "                        next_word = words[i][j+1]\n",
        "                    else:\n",
        "                        next_word = \"\"\n",
        "                    current_word = \" \".join([words[i][j], next_word])\n",
        "                train_words.append(re.sub('[^а-яА-Я]+', ' ', current_word).strip().lower())\n",
        "                if allophones != None:\n",
        "                    train_allophones.append(\" \".join(allophones[i][j]))\n",
        "    if allophones != None:\n",
        "        return train_words, train_allophones\n",
        "    else:\n",
        "        return train_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "espZoOpJp_cr"
      },
      "outputs": [],
      "source": [
        "train_words, train_allophones = create_feature(words, allophones)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJATIiOYp_cr",
        "outputId": "9e5e4e53-1d00-4339-cad5-b837c9db7905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['предисловие к', 'к русскому', 'русскому переводу', 'переводу', 'в течение']\n"
          ]
        }
      ],
      "source": [
        "print(train_words[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH50K8ZCp_cs",
        "outputId": "668c7e93-3316-495c-e040-15fc150f9943"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"p r' i1 d' i1 s l o0 v' i4 j i4\", 'k', 'r u0 s k a4 m u4', \"p' i1 r' i1 v o0 d u4\", 'f']\n"
          ]
        }
      ],
      "source": [
        "print(train_allophones[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPAGeSTHp_cs"
      },
      "source": [
        "# Загрузка модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-21T12:49:30.238441Z",
          "iopub.status.busy": "2023-11-21T12:49:30.237802Z",
          "iopub.status.idle": "2023-11-21T12:49:42.711669Z",
          "shell.execute_reply": "2023-11-21T12:49:42.710918Z",
          "shell.execute_reply.started": "2023-11-21T12:49:30.238406Z"
        },
        "id": "FJEj04L7p_cs",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "from huggingface_hub.hf_api import HfFolder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-21T12:49:42.714097Z",
          "iopub.status.busy": "2023-11-21T12:49:42.713007Z",
          "iopub.status.idle": "2023-11-21T12:49:42.718901Z",
          "shell.execute_reply": "2023-11-21T12:49:42.717794Z",
          "shell.execute_reply.started": "2023-11-21T12:49:42.714061Z"
        },
        "id": "nHfByyePp_cs",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "HfFolder.save_token('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')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "execution": {
          "iopub.execute_input": "2023-11-21T12:49:42.720436Z",
          "iopub.status.busy": "2023-11-21T12:49:42.720173Z",
          "iopub.status.idle": "2023-11-21T12:49:42.771859Z",
          "shell.execute_reply": "2023-11-21T12:49:42.770911Z",
          "shell.execute_reply.started": "2023-11-21T12:49:42.720412Z"
        },
        "id": "MM7srDqsp_cs",
        "outputId": "5c85e9c0-de1e-4b64-a5c8-46429b7fafbb",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-21T12:49:42.773386Z",
          "iopub.status.busy": "2023-11-21T12:49:42.773098Z",
          "iopub.status.idle": "2023-11-21T12:49:42.780418Z",
          "shell.execute_reply": "2023-11-21T12:49:42.779536Z",
          "shell.execute_reply.started": "2023-11-21T12:49:42.773360Z"
        },
        "id": "dnT4Rl7Sp_cs",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model_name = \"ai-forever/ruT5-base\"\n",
        "checkpoint = \"gnurtqh/ruT5-base-procody\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-11-21T12:49:42.784203Z",
          "iopub.status.busy": "2023-11-21T12:49:42.783930Z",
          "iopub.status.idle": "2023-11-21T12:50:26.922394Z",
          "shell.execute_reply": "2023-11-21T12:50:26.921398Z",
          "shell.execute_reply.started": "2023-11-21T12:49:42.784179Z"
        },
        "id": "8BTCxGd9p_cs",
        "outputId": "98848a4f-c5bb-4c55-b838-c8b6ded26a8c",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ],
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V_36qOjp_ct"
      },
      "source": [
        "# Создание датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-21T12:50:26.923754Z",
          "iopub.status.busy": "2023-11-21T12:50:26.923479Z",
          "iopub.status.idle": "2023-11-21T12:50:26.940682Z",
          "shell.execute_reply": "2023-11-21T12:50:26.939781Z",
          "shell.execute_reply.started": "2023-11-21T12:50:26.923720Z"
        },
        "id": "RQAebCtzp_ct",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataset import Dataset\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-21T12:50:26.942069Z",
          "iopub.status.busy": "2023-11-21T12:50:26.941807Z",
          "iopub.status.idle": "2023-11-21T12:50:29.716573Z",
          "shell.execute_reply": "2023-11-21T12:50:29.715774Z",
          "shell.execute_reply.started": "2023-11-21T12:50:26.942045Z"
        },
        "id": "SQE23_Hdp_ct",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_words, train_allophones, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-21T12:50:29.718042Z",
          "iopub.status.busy": "2023-11-21T12:50:29.717742Z",
          "iopub.status.idle": "2023-11-21T12:50:29.729045Z",
          "shell.execute_reply": "2023-11-21T12:50:29.728082Z",
          "shell.execute_reply.started": "2023-11-21T12:50:29.718018Z"
        },
        "id": "_aYH543tp_ct",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, tokenizer, train_words, train_allophones=None, train=True, max_source_length=512, max_target_length=128, padding=\"max_length\", truncation=True):\n",
        "        self.train_words = train_words\n",
        "        self.train_allophones = train_allophones\n",
        "        self.tokenizer = tokenizer\n",
        "        self.train = train\n",
        "        self.max_source_length = max_source_length\n",
        "        self.max_target_length = max_target_length\n",
        "        self.padding = padding\n",
        "        self.truncation = truncation\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.train_words)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        source_text = self.train_words[index]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            source_text,\n",
        "            max_length=self.max_source_length,\n",
        "            padding=self.padding,\n",
        "            truncation=self.truncation,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        if self.train == True:\n",
        "            target_text = self.train_allophones[index]\n",
        "            labels = self.tokenizer(\n",
        "                target_text,\n",
        "                max_length=self.max_target_length,\n",
        "                padding=self.padding,\n",
        "                truncation=self.truncation,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "            return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
        "            \"labels\": labels[\"input_ids\"].flatten()\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
        "                \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
        "            }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-21T12:50:29.730278Z",
          "iopub.status.busy": "2023-11-21T12:50:29.730041Z",
          "iopub.status.idle": "2023-11-21T12:50:29.742284Z",
          "shell.execute_reply": "2023-11-21T12:50:29.741447Z",
          "shell.execute_reply.started": "2023-11-21T12:50:29.730258Z"
        },
        "id": "S9515Lljp_ct",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(tokenizer, X_train, y_train)\n",
        "test_dataset = CustomDataset(tokenizer, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEaOo7-Vp_ct"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-21T12:50:29.753305Z",
          "iopub.status.busy": "2023-11-21T12:50:29.753071Z",
          "iopub.status.idle": "2023-11-21T12:50:29.761687Z",
          "shell.execute_reply": "2023-11-21T12:50:29.760949Z",
          "shell.execute_reply.started": "2023-11-21T12:50:29.753284Z"
        },
        "id": "8cdT0wpCp_ct",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "mode = \"train\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvZglagRp_ct"
      },
      "source": [
        "# Тестирование модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-21T12:50:29.743947Z",
          "iopub.status.busy": "2023-11-21T12:50:29.743384Z",
          "iopub.status.idle": "2023-11-21T12:50:29.751717Z",
          "shell.execute_reply": "2023-11-21T12:50:29.750934Z",
          "shell.execute_reply.started": "2023-11-21T12:50:29.743915Z"
        },
        "id": "AqWsJHRtp_ct",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-21T12:50:29.762880Z",
          "iopub.status.busy": "2023-11-21T12:50:29.762619Z",
          "iopub.status.idle": "2023-11-21T12:59:59.713684Z",
          "shell.execute_reply": "2023-11-21T12:59:59.712614Z",
          "shell.execute_reply.started": "2023-11-21T12:50:29.762857Z"
        },
        "id": "0nv8bfLlp_ct",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "if mode ==\"test\":\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    labels = []\n",
        "\n",
        "    for batch in tqdm(test_dataloader):\n",
        "        inputs = batch['input_ids'].to(device)\n",
        "        labels_batch = batch['labels'].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(input_ids=inputs)\n",
        "        predictions.extend(outputs.tolist())\n",
        "        labels.extend(labels_batch.tolist())\n",
        "\n",
        "    predictions = [tokenizer.decode(item, skip_special_tokens=True) for item in predictions]\n",
        "    labels = [tokenizer.decode(item, skip_special_tokens=True) for item in labels]\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "\n",
        "    print(f\"WRR: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbEILeDlp_ct"
      },
      "source": [
        "# Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "execution": {
          "iopub.execute_input": "2023-11-21T12:59:59.715716Z",
          "iopub.status.busy": "2023-11-21T12:59:59.715297Z",
          "iopub.status.idle": "2023-11-21T12:59:59.722257Z",
          "shell.execute_reply": "2023-11-21T12:59:59.721224Z",
          "shell.execute_reply.started": "2023-11-21T12:59:59.715677Z"
        },
        "id": "EQ4LiRfop_ct",
        "outputId": "345fcefa-614a-404f-cd1e-a3d341d95fa4",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='168' max='6016' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 168/6016 03:30 < 2:03:35, 0.79 it/s, Epoch 0.03/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if mode ==\"train\":\n",
        "    training_args = Seq2SeqTrainingArguments(\n",
        "        output_dir=\"ruT5-base-procody\",\n",
        "        per_device_train_batch_size=8,\n",
        "        num_train_epochs=1,\n",
        "        evaluation_strategy=\"steps\",\n",
        "        eval_steps=500,\n",
        "        save_total_limit=3,\n",
        "        push_to_hub=True,\n",
        "    )\n",
        "\n",
        "    trainer = Seq2SeqTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=test_dataset,\n",
        "    )\n",
        "    trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jowVYB0Kp_cu"
      },
      "source": [
        "# Предсказание"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcEjSY4Jp_cu"
      },
      "outputs": [],
      "source": [
        "if mode ==\"predict\":\n",
        "    input_words, _ = parse_xml_file('./data/input.xml')\n",
        "    input_feature = create_feature(input_words)\n",
        "    input_dataset = CustomDataset(tokenizer, input_feature, train=False)\n",
        "    input_dataloader = DataLoader(input_dataset, batch_size=4, shuffle=False)\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "    for batch in tqdm(input_dataloader):\n",
        "        inputs = batch['input_ids'].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(input_ids=inputs)\n",
        "        predictions.extend(outputs.tolist())\n",
        "\n",
        "    predictions = [tokenizer.decode(item, skip_special_tokens=True) for item in predictions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUqR0sOTp_cu"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "for i in range(len(input_words)):\n",
        "    results.append(\n",
        "        {\n",
        "            \"content\": input_words[i],\n",
        "            \"allophones\": predictions[i].split()\n",
        "        }\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Zdc6MRfp_cu"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open(\"./data/output.json\", 'w', encoding='utf-8') as json_file:\n",
        "    json.dump([{\"words\": results}], json_file, ensure_ascii=False, indent=4)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4027599,
          "sourceId": 7005890,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30588,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
